{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c826f7fa-d701-4778-9fb7-b5da672cbe1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c826f7fa-d701-4778-9fb7-b5da672cbe1d",
        "outputId": "7f29ecbd-7100-49fb-c417-d56d4e5dd4f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.4\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.1)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.13.0)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: jiwer\n",
            "Successfully installed jiwer-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-Levenshtein\n",
        "!pip install evaluate\n",
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cd7d03f-2732-4215-8e4d-7ee7b49eb3be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "dc713efb6db5411aa1b8dd8877ee1fcc",
            "554720a814cc466a8e281fcb02d8a28a"
          ]
        },
        "id": "3cd7d03f-2732-4215-8e4d-7ee7b49eb3be",
        "outputId": "0d1e2582-e3d2-41f0-afe9-3e1354ef1c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc713efb6db5411aa1b8dd8877ee1fcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "554720a814cc466a8e281fcb02d8a28a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from evaluate import load\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "from difflib import SequenceMatcher\n",
        "# import Levenshtein\n",
        "\n",
        "cer_metric = load(\"cer\")\n",
        "wer_metric = load(\"wer\")\n",
        "\n",
        "def compute_metrics(predicted_text, reference_text):\n",
        "    \"\"\"\n",
        "    Compute various text similarity metrics between predicted and reference text.\n",
        "\n",
        "    Args:\n",
        "        predicted_text (str or list): The predicted text(s)\n",
        "        reference_text (str or list): The reference/ground truth text(s)\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing metrics\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert single strings to lists\n",
        "    if isinstance(predicted_text, str):\n",
        "        predicted_text = [predicted_text]\n",
        "    if isinstance(reference_text, str):\n",
        "        reference_text = [reference_text]\n",
        "\n",
        "    # Compute CER and WER\n",
        "    cer_score = cer_metric.compute(predictions=predicted_text, references=reference_text)\n",
        "    wer_score = wer_metric.compute(predictions=predicted_text, references=reference_text)\n",
        "\n",
        "    # Levenshtein distance\n",
        "    lev_dist = levenshtein_distance(predicted_text[0], reference_text[0])\n",
        "    # similarity = Levenshtein.ratio(predicted_text[0], reference_text[0])\n",
        "\n",
        "    # Similarity score (0-1)\n",
        "    seq_matcher = SequenceMatcher(None, predicted_text[0], reference_text[0])\n",
        "    similarity = seq_matcher.ratio()\n",
        "\n",
        "    return {\n",
        "        \"cer\": cer_score,\n",
        "        \"wer\": wer_score,\n",
        "        \"levenshtein_distance\": lev_dist,\n",
        "        \"similarity_score\": similarity,\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5ab78fd-403a-4bba-aeb5-6fc8b398e382",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5ab78fd-403a-4bba-aeb5-6fc8b398e382",
        "outputId": "b82fdcae-5c08-44b8-fcd4-8422ba580bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cer': 0.0, 'wer': 0.0, 'levenshtein_distance': 0, 'similarity_score': 1.0}\n"
          ]
        }
      ],
      "source": [
        "reference = 'matar'\n",
        "\n",
        "\n",
        "# predicted = 'matar al enemigs que debia precaverfé, aurique le halle inerme, indefensa'\n",
        "predicted = 'matar'\n",
        "\n",
        "result = compute_metrics(predicted,reference)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b25bae8-d17d-4ba4-a3f3-c4c173b7f20d",
      "metadata": {
        "id": "3b25bae8-d17d-4ba4-a3f3-c4c173b7f20d"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "cer_metric = load(\"cer\")\n",
        "wer_metric = load(\"wer\")\n",
        "\n",
        "def compute_metrics(predicted_text, reference_text):\n",
        "    \"\"\"\n",
        "    Compute various text similarity metrics between predicted and reference text.\n",
        "\n",
        "    Args:\n",
        "        predicted_text (str or list): The predicted text(s)\n",
        "        reference_text (str or list): The reference/ground truth text(s)\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing metrics\n",
        "    \"\"\"\n",
        "\n",
        "    if isinstance(predicted_text, str):\n",
        "        predicted_text = [predicted_text]\n",
        "    if isinstance(reference_text, str):\n",
        "        reference_text = [reference_text]\n",
        "\n",
        "    # Compute CER and WER\n",
        "    cer_score = cer_metric.compute(predictions=predicted_text, references=reference_text)\n",
        "    wer_score = wer_metric.compute(predictions=predicted_text, references=reference_text)\n",
        "\n",
        "    levenshtein_distances = []\n",
        "    similarity_scores = []\n",
        "    for pred, ref in zip(predicted_text, reference_text):\n",
        "\n",
        "        # Levenshtein distance\n",
        "        lev_dist = levenshtein_distance(pred, ref)\n",
        "        levenshtein_distances.append(lev_dist)\n",
        "\n",
        "        # Similarity score (0-1)\n",
        "        seq_matcher = SequenceMatcher(None, pred, ref)\n",
        "        similarity = seq_matcher.ratio()\n",
        "        similarity_scores.append(similarity)\n",
        "\n",
        "    # Calculate averages if multiple samples\n",
        "    avg_lev_dist = sum(levenshtein_distances) / len(levenshtein_distances)\n",
        "    avg_similarity = sum(similarity_scores) / len(similarity_scores)\n",
        "\n",
        "    return {\n",
        "        \"cer\": cer_score,\n",
        "        \"wer\": wer_score,\n",
        "        \"levenshtein_distance\": avg_lev_dist,\n",
        "        \"similarity_score\": avg_similarity,\n",
        "        \"all_levenshtein_distances\": levenshtein_distances,\n",
        "        \"all_similarity_scores\": similarity_scores\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6648efa0-40e2-43e4-aa11-8a4d5f249759",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6648efa0-40e2-43e4-aa11-8a4d5f249759",
        "outputId": "00e5dbd3-9925-4503-829c-3b8bedbf8c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cer': 0.8333333333333334, 'wer': 0.5, 'levenshtein_distance': 2.5, 'similarity_score': 0.5, 'all_levenshtein_distances': [5, 0], 'all_similarity_scores': [0.0, 1.0]}\n"
          ]
        }
      ],
      "source": [
        "reference = ['matar',\n",
        "             'ô']\n",
        "\n",
        "# predicted = ['matar al enemigs que debia precaverfé, aurique le halle inerme, indefensa',\n",
        "#              'ô fe le acometa feguto, è por por la elpalda, ô con arma de luego,ô con ve-']\n",
        "\n",
        "predicted = ['',\n",
        "             'ô']\n",
        "\n",
        "result = compute_metrics(predicted,reference)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feba99d5"
      },
      "source": [
        "import json\n",
        "\n",
        "def evaluate_submission(submission_json_path, label_json_path):\n",
        "    \"\"\"\n",
        "    Evaluates the actual submission files against the corresponding label files.\n",
        "\n",
        "    The submission file is a JSON file with the following structure:\n",
        "    {\"file_path\": [xxx, yyy, ...], \"prediction\": [xxx, yyy, ...]}\n",
        "    'file_path' represents the file paths of the data in the target dataset.\n",
        "    'prediction' represents the output strings from the participant's model.\n",
        "\n",
        "    The label file is also a JSON file with the following structure:\n",
        "    {\"file_path\": [xxx, yyy, ...], \"label\": [xxx, yyy, ...]}\n",
        "    'file_path' represents the file paths of the data in the target dataset.\n",
        "    'label' represents the ground truth strings for the data.\n",
        "    \"\"\"\n",
        "    with open(submission_json_path, 'r') as f:\n",
        "        submission = json.load(f)\n",
        "\n",
        "    with open(label_json_path, 'r') as f:\n",
        "        labels = json.load(f)\n",
        "\n",
        "    # Create dictionaries for easier lookup by file_path\n",
        "    submission_dict = dict(zip(submission['file_path'], submission['prediction']))\n",
        "    labels_dict = dict(zip(labels['file_path'], labels['label']))\n",
        "\n",
        "    # Align predictions and references based on file_path\n",
        "    predictions = []\n",
        "    references = []\n",
        "    for file_path in labels['file_path']:\n",
        "        if file_path in submission_dict:\n",
        "            predictions.append(submission_dict[file_path].lower())\n",
        "            references.append(labels_dict[file_path].lower())\n",
        "        else:\n",
        "            # Handle cases where a file_path in labels is not in submission\n",
        "            print(f\"Warning: File path '{file_path}' not found in submission file.\")\n",
        "            predictions.append(\"\")\n",
        "            references.append(labels_dict[file_path])\n",
        "\n",
        "\n",
        "    # Compute metrics using the existing compute_metrics function\n",
        "    results = compute_metrics(predictions, references)\n",
        "\n",
        "    return results"
      ],
      "id": "feba99d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = {\n",
        "    'file_path' : ['book1_page1','book1_page2','book2_page1'],\n",
        "    'label' : [\n",
        "        \"SI POR evitar UN pecado mortal\",\n",
        "        \"aveys de poner vuestra vida en pe\",\n",
        "        \"ligro arriesgalda QUE es el mejor\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "label_object = json.dumps(label, indent=4)\n",
        "save_path = 'label.json'\n",
        "with open(save_path, 'w') as f:\n",
        "    f.write(label_object)\n",
        "\n",
        "submission = {\n",
        "    'file_path' : ['book1_page1','book1_page2','book2_page1'],\n",
        "    'prediction' : [\n",
        "        \"Si por euitar n pecado mortal\",\n",
        "        \"aueys de poner uuestra uida en pe\",\n",
        "        \"ligro arriesgalda que es el mejor\",\n",
        "    ]\n",
        "\n",
        "}\n",
        "\n",
        "submission_object = json.dumps(submission, indent=4)\n",
        "save_path = 'submission.json'\n",
        "with open(save_path, 'w') as f:\n",
        "    f.write(submission_object)\n",
        "\n",
        "\n",
        "label_json_path = 'label.json'\n",
        "submission_json_path = 'submission.json'\n",
        "\n",
        "results = evaluate_submission(submission_json_path, label_json_path)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "3xXW7zUmgWD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "776cbc8d-dff2-448e-a076-c52ed815ab99"
      },
      "id": "3xXW7zUmgWD7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cer': 0.052083333333333336, 'wer': 0.2631578947368421, 'levenshtein_distance': 1.6666666666666667, 'similarity_score': 0.9527478171545969, 'all_levenshtein_distances': [2, 3, 0], 'all_similarity_scores': [0.9491525423728814, 0.9090909090909091, 1.0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# When missing entry in submission file\n",
        "# Ground truth (label.json)\n",
        "label = {\n",
        "    \"file_path\": [\n",
        "        \"book1_page1\",\n",
        "        \"book1_page2\",\n",
        "        \"book1_page3\",\n",
        "        \"book1_page4\",\n",
        "        \"book1_page5\",\n",
        "        \"book1_page6\",\n",
        "        \"book1_page7\"\n",
        "    ],\n",
        "    \"label\": [\n",
        "        \"Si por evitar un pecado mortal\",\n",
        "        \"aveys de poner vuestra vida en pe\",\n",
        "        \"ligro arriesgalda que es el mejor\",\n",
        "        \"empleo que della podeys hazer y\",\n",
        "        \"de vuestra hazienda para este fin en\",\n",
        "        \"redemir cautivos y sacar mugeres\",\n",
        "        \"de pecado dotandolas liberalmen\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "submission = {\n",
        "    \"file_path\": [\n",
        "        \"book1_page1\",\n",
        "        \"book1_page2\",\n",
        "        \"book1_page3\",\n",
        "        \"book1_page5\",\n",
        "        \"book1_page6\",\n",
        "        \"book1_page7\"\n",
        "    ],\n",
        "    \"prediction\": [\n",
        "        \"si por euitar n pecado mortal\",\n",
        "        \"aueys de poner uuestra uida en pe\",\n",
        "        \"ligro arriesgalda que es el mejor\",\n",
        "        \"hazienda para este fin en\",\n",
        "        \"redemir cautiuos y sacar mugeres\",\n",
        "        \"de pecado dotandolas liberalmen\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open('label1.json', 'w') as f:\n",
        "    json.dump(label, f, indent=4)\n",
        "\n",
        "with open('submission1.json', 'w') as f:\n",
        "    json.dump(submission, f, indent=4)\n"
      ],
      "metadata": {
        "id": "B6YjbsIxhvYI"
      },
      "id": "B6YjbsIxhvYI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_json_path = 'label1.json'\n",
        "submission_json_path = 'submission1.json'\n",
        "\n",
        "results = evaluate_submission(submission_json_path, label_json_path)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "go87hzn4hQc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf6afa9-73f7-419b-827c-50358005bae7"
      },
      "id": "go87hzn4hQc6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: File path 'book1_page4' not found in submission file.\n",
            "{'cer': 0.21238938053097345, 'wer': 0.34146341463414637, 'levenshtein_distance': 6.857142857142857, 'similarity_score': 0.8066665118016189, 'all_levenshtein_distances': [2, 3, 0, 31, 11, 1, 0], 'all_similarity_scores': [0.9491525423728814, 0.9090909090909091, 1.0, 0.0, 0.819672131147541, 0.96875, 1.0]}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}